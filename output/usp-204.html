<!DOCTYPE html>
<html lang="en">
  <head>
     <title> @iosifache | Ubuntu Security Podcast 204 </title>

    <meta charset="utf-8" />
    <meta name="generator" content="Pelican" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@picocss/pico@1/css/pico.min.css"
    />
    <link rel="stylesheet" href="/theme/css/style.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100;300;400;500;700;800&display=swap"
      rel="stylesheet"
    />

    <link rel="icon" href="/theme/images/favicon.png" type="image/x-icon" />
           <meta name="tags" content="research" />
<meta name="tags" content="machine-learning" />
<meta name="tags" content="federated-learning" />
<meta name="tags" content="backdoor-attacks" />
<meta name="tags" content="podcast" />
   </head>

  <body>
    <main class="container">
      <nav>
        <ul>
          <li>
            <strong>
              <a href="/"
                >@iosifache</a
              >
            </strong>
          </li>
        </ul>
        <ul>
          <li><a href="/">Articles</a></li>
          <li><a href="/talks">Talks</a></li>
          <li><a href="/almanach">Almanach</a></li>
          <li><a href="/about">About</a></li>
          <li><a href="/now">Now</a></li>
        </ul>
      </nav>
<h1 class="entry-title">
  <a
    href="/usp-204.html"
    rel="bookmark"
    title="Permalink to Ubuntu Security Podcast 204"
    >Ubuntu Security Podcast 204</a
  >
</h1>
<div class="post-info">
  <b>Last updated</b>:
  <time class="published" datetime="2023-08-06T00:00:00+03:00">
    Sun 06 August 2023
  </time>
    <div class="tags">
    <b>Tags</b>:     <a href="/tag/research.html"
      ><small class="chip">research</small></a
    >
    <a href="/tag/machine-learning.html"
      ><small class="chip">machine-learning</small></a
    >
    <a href="/tag/federated-learning.html"
      ><small class="chip">federated-learning</small></a
    >
    <a href="/tag/backdoor-attacks.html"
      ><small class="chip">backdoor-attacks</small></a
    >
    <a href="/tag/podcast.html"
      ><small class="chip">podcast</small></a
    >
  </div>
</div>
<br /><br />
<h1>Ubuntu Security Podcast Episode</h1>
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/7kOxT9HnjkUH6EDYSvow6M" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

<h1>Paper</h1>
<ul>
<li>Paper: "FLAME: Taming Backdoors in Federated Learning"</li>
<li>Abstract</li>
</ul>
<blockquote>
<p>Federated Learning (FL) is a collaborative machine learning approach allowing participants to jointly train a model without having to share their private, potentially sensitive local datasets with others. Despite its benefits, FL is vulnerable to so-called backdoor attacks, in which an adversary injects manipulated model updates into the federated model aggregation process so that the resulting model will provide targeted false predictions for specific adversary-chosen inputs. Proposed defenses against backdoor attacks based on detecting and filtering out malicious model updates consider only very specific and limited attacker models, whereas defenses based on differential privacy-inspired noise injection significantly deteriorate the benign performance of the aggregated model. To address these deficiencies, we introduce FLAME, a defense framework that estimates the sufficient amount of noise to be injected to ensure the elimination of backdoors. To minimize the required amount of noise, FLAME uses a model clustering and weight clipping approach. This ensures that FLAME can maintain the benign performance of the aggregated model while effectively eliminating adversarial backdoors. Our evaluation of FLAME on several datasets stemming from application areas including image classification, word prediction, and IoT intrusion detection demonstrates that FLAME removes backdoors effectively with a negligible impact on the benign performance of the models.</p>
</blockquote>
<ul>
<li>CCS concepts (unofficial)<ul>
<li>Security and privacy - Systems security - Distributed systems security</li>
<li>Computing methodologies - Machine learning - Machine learning approaches</li>
</ul>
</li>
<li>Publishing date: January 2021</li>
<li>PDF: <a class="external-links" href="https://www.usenix.org/system/files/sec22-nguyen.pdf">USENIX</a></li>
</ul>     </main>
  </body>
</html>